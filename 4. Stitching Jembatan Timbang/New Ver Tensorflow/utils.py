import cv2
import numpy as np


import os

os.environ["TF_CPP_MIN_LOG_LEVEL"] = (
    "3"  # or any {'0', '1', '2'} to control the verbosity
)
import cv2
import numpy as np
import time
from ultralytics import YOLO
from collections import deque

from libs.bbox3d_utils import *
from libs.Plotting import *
from model import model_mobilenet, orientation_loss

tracking_trajectories = {}
bin_size = 6
input_shape = (224, 224, 3)
trained_classes = ["ball", "box", "cylinder"]
yolo_classes = ["ball", "box", "cylinder"]
P2 = np.array(
    [
        [772.54833996, 0.0, 320.0, 0.0],
        [0.0, 772.54833996, 320.0, -0.6],
        [0.0, 0.0, 1.0, 2.0],
    ]
)
dims_avg = {
    "ball": np.array([0.05, 0, 0.1]),
    "box": np.array([0.05, 0, 0.1]),
    "cylinder": np.array([0.05, 0, 0.1]),
}
# print(dims_avg)


def process2D(bbox2d_model, image, track=True, device="cpu"):
    bboxes = []
    if track is True:
        results = bbox2d_model.track(image, verbose=False, device=device, persist=True)

        for id_ in list(tracking_trajectories.keys()):
            if id_ not in [
                int(bbox.id)
                for predictions in results
                if predictions is not None
                for bbox in predictions.boxes
                if bbox.id is not None
            ]:
                del tracking_trajectories[id_]

        for predictions in results:
            if predictions is None:
                continue

            if predictions.boxes is None or predictions.boxes.id is None:
                continue

            for bbox in predictions.boxes:
                ## object detections
                for scores, classes, bbox_coords, id_ in zip(
                    bbox.conf, bbox.cls, bbox.xyxy, bbox.id
                ):
                    xmin = bbox_coords[0]
                    ymin = bbox_coords[1]
                    xmax = bbox_coords[2]
                    ymax = bbox_coords[3]
                    cv2.rectangle(
                        image,
                        (int(xmin), int(ymin)),
                        (int(xmax), int(ymax)),
                        (0, 0, 225),
                        2,
                    )
                    bboxes.append([bbox_coords, scores, classes, id_])

                    label = (
                        " "
                        + f"ID: {int(id_)}"
                        + " "
                        + str(predictions.names[int(classes)])
                        + " "
                        + str(round(float(scores) * 100, 1))
                        + "%"
                    )
                    text_size = cv2.getTextSize(label, cv2.FONT_HERSHEY_SIMPLEX, 2, 1)
                    dim, baseline = text_size[0], text_size[1]
                    cv2.rectangle(
                        image,
                        (int(xmin), int(ymin)),
                        ((int(xmin) + dim[0] // 3) - 20, int(ymin) - dim[1] + baseline),
                        (30, 30, 30),
                        cv2.FILLED,
                    )
                    cv2.putText(
                        image,
                        label,
                        (int(xmin), int(ymin) - 7),
                        cv2.FONT_HERSHEY_SIMPLEX,
                        0.5,
                        (255, 255, 255),
                        1,
                    )

                    centroid_x = (xmin + xmax) / 2
                    centroid_y = (ymin + ymax) / 2

                    # Append centroid to tracking_points
                    if id_ is not None and int(id_) not in tracking_trajectories:
                        tracking_trajectories[int(id_)] = deque(maxlen=5)
                    if id_ is not None:
                        tracking_trajectories[int(id_)].append((centroid_x, centroid_y))

                # Draw trajectories
                for id_, trajectory in tracking_trajectories.items():
                    for i in range(1, len(trajectory)):
                        thickness = int(2 * (i / len(trajectory)) + 1)
                        cv2.line(
                            image,
                            (int(trajectory[i - 1][0]), int(trajectory[i - 1][1])),
                            (int(trajectory[i][0]), int(trajectory[i][1])),
                            (255, 255, 255),
                            thickness,
                        )

                ## object segmentations
                # for mask in masks.xy:
                #     polygon = mask
                #     cv2.polylines(image, [np.int32(polygon)], True, (255, 0, 0), thickness=2)

    if not track:
        results = bbox2d_model.predict(
            image, verbose=False, device=device
        )  # predict on an image
        for predictions in results:
            if predictions is None:
                continue  # Skip this image if YOLO fails to detect any objects
            if predictions.boxes is None:
                continue  # Skip this image if there are no boxes or masks

            for bbox in predictions.boxes:
                ## object detections
                for scores, classes, bbox_coords in zip(bbox.conf, bbox.cls, bbox.xyxy):
                    xmin = bbox_coords[0]
                    ymin = bbox_coords[1]
                    xmax = bbox_coords[2]
                    ymax = bbox_coords[3]
                    cv2.rectangle(
                        image,
                        (int(xmin), int(ymin)),
                        (int(xmax), int(ymax)),
                        (0, 0, 225),
                        2,
                    )
                    bboxes.append([bbox_coords, scores, classes])

                    label = (
                        " "
                        + str(predictions.names[int(classes)])
                        + " "
                        + str(round(float(scores) * 100, 1))
                        + "%"
                    )
                    text_size = cv2.getTextSize(label, cv2.FONT_HERSHEY_SIMPLEX, 2, 1)
                    dim, baseline = text_size[0], text_size[1]
                    cv2.rectangle(
                        image,
                        (int(xmin), int(ymin)),
                        ((int(xmin) + dim[0] // 3) - 20, int(ymin) - dim[1] + baseline),
                        (30, 30, 30),
                        cv2.FILLED,
                    )
                    cv2.putText(
                        image,
                        label,
                        (int(xmin), int(ymin) - 7),
                        cv2.FONT_HERSHEY_SIMPLEX,
                        0.5,
                        (255, 255, 255),
                        1,
                    )

    return image, bboxes


def process3D(bbox3d_model, frame, img, bboxes2d):
    DIMS = []
    bboxes = []
    for item in bboxes2d:
        bbox_coords, scores, classes, *id_ = item if len(item) == 4 else (*item, None)
        padding = 0  # Set the padding value
        xmin = max(0, bbox_coords[0] - padding)
        ymin = max(0, bbox_coords[1] - padding)
        xmax = min(frame.shape[1], bbox_coords[2] + padding)
        ymax = min(frame.shape[0], bbox_coords[3] + padding)
        objID = id_

        crop = img[int(ymin) : int(ymax), int(xmin) : int(xmax)]
        patch = tf.convert_to_tensor(crop, dtype=tf.float32)
        patch /= 255.0  # Normalize to [0,1]
        patch = tf.image.resize(patch, (224, 224))  # Resize to 224x224
        patch = tf.expand_dims(patch, axis=0)  # Equivalent to reshape((1, *crop.shape))
        prediction = bbox3d_model.predict(patch, verbose=0)

        dim = prediction[0][0]
        # print("dim prediction:",dim)
        bin_anchor = prediction[1][0]
        bin_confidence = prediction[2][0]

        ###refinement dimension
        try:
            dim = [0.04, 0.04, 0.04]
            DIMS.append(dim)
        except:
            dim = DIMS[-1]

        bbox_ = [int(xmin), int(ymin), int(xmax), int(ymax)]
        theta_ray = calc_theta_ray(frame, bbox_, P2)
        # update with predicted alpha, [-pi, pi]
        alpha = recover_angle(bin_anchor, bin_confidence, bin_size)
        alpha = alpha - theta_ray

        # calculate the location   # plot 3d bbox
        location, x = calc_location(
            dimension=dim,
            proj_matrix=P2,
            box_2d=bbox_,
            alpha=alpha,
            theta_ray=theta_ray,
        )
        # print("location:",location)
        bboxes.append(
            [
                bbox_,
                dim,
                alpha,
                theta_ray,
                bin_anchor,
                bin_confidence,
                classes,
                location,
                objID,
            ]
        )

    return bboxes
